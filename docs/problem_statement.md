----- Problem Statement-----

Traditional examination evaluation methods rely heavily on post-exam analysis,
where question difficulty is inferred only after students attempt the exam,
typically using average scores or pass rates. This approach does not support
pre-exam assessment design and offers limited insight into question quality.

This project aims to design and implement a machine learning and NLP-based
educational analytics system that analyzes exam-style questions using textual
features and historical learner performance proxies to classify question
difficulty.

Milestone 1 focuses on building a supervised learning pipeline that predicts
question difficulty (Easy, Medium, Hard) and provides analytical insights
through a basic user interface, enabling both pre-exam prediction and post-exam
analysis.
